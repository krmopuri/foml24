---
type: lecture
date: 21-09-24
title: (dl-03) Representational Power of an MLP

# optional
# please use /static_files/notes directory to store notes
# thumbnail: /static_files/path/to/image.jpg

# optional
tldr: "Multi Layered Network of Neurons can represent any artbirary function!"
  
# optional
# set it to true if you dont want this lecture to appear in the updates section
hide_from_announcments: false

# optional
links: 
    - url: https://colab.research.google.com/drive/1fzr4NCQP9ScZM8ZPV0z56QJGv6qJrnuy?usp=sharing
      name: ReLU-activation-code
    - url: https://colab.research.google.com/drive/1dAtMK4jwcsHSxgodumkoV_pD0O0RrQrz?usp=sharing
      name: sigmoid-activation-codes
    - url: /static_files/presentations/dl-03.pdf
      name: slides
    #- url: /static_files/presentations/lec.zip
    #  name: other
---

**Suggested Readings:**

- [Chapter 4 of Michael Nielson's NNDL book](http://neuralnetworksanddeeplearning.com/chap4.html)
- [Deep Mind Blog on Universal Approximation Theorem](https://www.deep-mind.org/2023/03/26/the-universal-approximation-theorem/#Universal_Approximation_Theorem)
- [Approximation by Superposition of Sigmoid Functions](https://web.njit.edu/~usman/courses/cs675_fall18/10.1.1.441.7873.pdf)
- [Approximation Capabilities of Muitilayer
Feedforward Networks](https://web.njit.edu/~usman/courses/cs677_spring21/hornik-nn-1991.pdf)

